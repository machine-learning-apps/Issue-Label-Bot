{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# so I don't \n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"  #prevent access to GPU for inference\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = 150\n",
    "pd.options.display.max_colwidth = 500\n",
    "import json\n",
    "from mdparse import transform_pre_rules, compose\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-83338dcfe66a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "assert not torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at Data For Kubeflow/Kubeflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Kubeflow Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " See the query in [GCP BigQuery Console](https://console.cloud.google.com/bigquery?sq=1073071082706:92b4ec67dbf5441ba95eb5b9d77e8993)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'https://storage.googleapis.com/issue_label_bot/kubeflow_issues/000000000000.csv')\n",
    "# filter for kubeflow/kubeflow\n",
    "kfdf = df[df.repo.apply(lambda x: x.split('/')[1] =='kubeflow')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten list of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unpack the lists of labels and flatten\n",
    "def unpack_list(x):\n",
    "    \"convert list as string into list.\"\n",
    "    if x == '':\n",
    "        return 'no_labels'\n",
    "    else:\n",
    "        return json.loads(x)\n",
    "\n",
    "#flatten lists\n",
    "labels = []\n",
    "label_series = kfdf.labels.apply(lambda x: unpack_list(x))\n",
    "for x in label_series:\n",
    "    labels.extend(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 10 / Bottom 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "priority/p1           534\n",
       "priority/p2           148\n",
       "area/jupyter          142\n",
       "platform/gcp          128\n",
       "area/kfctl            114\n",
       "release/0.3.0          98\n",
       "community/question     96\n",
       "area/0.4.0             90\n",
       "area/bootstrap         83\n",
       "priority/p0            62\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "platform/minikf           1\n",
       "p1-important              1\n",
       "platform/aws              1\n",
       "area/openvino             1\n",
       "area/centraldashbosard    1\n",
       "area/design               1\n",
       "cloud/azure               1\n",
       "approved                  1\n",
       "area/horovod              1\n",
       "area/chainer              1\n",
       "Name: labels, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_counts = pd.DataFrame({'labels': labels}).labels.value_counts()\n",
    "display(label_counts.head(10))\n",
    "display(label_counts.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Borrowed this from nb 2\n",
    "def process_dict(dfdict, _):\n",
    "    \"\"\"process the data, but allow failure.\"\"\"\n",
    "    t = compose(transform_pre_rules)\n",
    "    title = dfdict['title']\n",
    "    body = dfdict['body']\n",
    "    try:\n",
    "        text = 'xxxfldtitle '+ t(title) + ' xxxfldbody ' + t(body)\n",
    "    except:\n",
    "        return None\n",
    "    return {'url': dfdict['url'], 'text':text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': '\"https://github.com/kubeflow/kubeflow/issues/574\"',\n",
       "  'text': \"xxxfldtitle tfjobs ui doesn't work behind iap; react app needs support iap? xxxfldbody tfjobs ui is deployed on dev.kubeflow.org. \\\\ r \\\\ r the ui shows up behind iap but its doesn't work \\\\ r - no tfjobs are listed \\\\ r - creating a job via the ui doesn't work. \\\\ r \\\\ r looking at the developer console we see requests to \\\\ r \\\\ r \\\\ r *URL* xxxlnkhb accounts.google.com xxxlnkhe \\\\ r \\\\ r which suggests to me the request is hitting the loadbalancer and being directed to do auth verification to sign in and its getting rejected. \\\\ r \\\\ r so i think one of two things is happening \\\\ r \\\\ r 1. the request is coming from the server running in k8s and incorrectly being redirected to the external loadbalncer and thus hitting iap when it shouldn't be \\\\ r 1. the request is coming from the client and the client needs to be updated to support iap. \\\\ r \\\\ r xxxatmention do you know where the request is coming from? \\\\ r \\\\ r you should be able to access it at \\\\ r *URL* xxxlnkhb dev.kubeflow.org xxxlnkhe\"},\n",
       " {'url': '\"https://github.com/kubeflow/kubeflow/issues/950\"',\n",
       "  'text': \"xxxfldtitle gcp cluster-kubeflow.yaml isn't tested xxxfldbody this is the recommended dm and bootstrapper config for gke deployments. \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r it doesn't like that yaml file is used by our e2e tests because it wasn't updated to specify the registry when that change was made to \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r there is also another gcp bootstrapper config in that directory \\\\ r \\\\ r our e2e tests are using this dm config \\\\ r *URL* xxxlnkhb github.com xxxlnkhe \\\\ r we do need to make changes to the dm config in order to pull the registry at head. \\\\ r \\\\ r we have two options \\\\ r \\\\ r 1. we could create a separate test for *URL* xxxlnkhb github.com xxxlnkhe 1. we could make the necessary modifications to *URL* xxxlnkhb github.com xxxlnkhe \\\\ r we could use a simple shell script that runs jq to make the necessary field changes \\\\ r \\\\ r i prefer 2. if we use jq then we could update the instructions *URL* xxxlnkhb github.com xxxlnkhe to use the same jq commands. \\\\ r \\\\ r xxxatmention thoughts?\"}]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_issue_texts = [process_dict(x, 0) for x in kfdf.to_dict(orient='rows')]\n",
    "processed_issue_texts[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: you can export a lightweight learner for inference per https://docs.fast.ai/tutorial.inference.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.701002</td>\n",
       "      <td>3.515886</td>\n",
       "      <td>0.376756</td>\n",
       "      <td>15:39:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3.691734</td>\n",
       "      <td>3.512343</td>\n",
       "      <td>0.377202</td>\n",
       "      <td>33:23:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3.699855</td>\n",
       "      <td>3.509445</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>15:40:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  valid_loss  accuracy      time\n",
       "0      0    3.701002    3.515886  0.376756  15:39:27\n",
       "1      1    3.691734    3.512343  0.377202  33:23:22\n",
       "2      2    3.699855    3.509445  0.377600  15:40:10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('lang_model_onecycle_resume/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3.726073</td>\n",
       "      <td>3.523209</td>\n",
       "      <td>0.375969</td>\n",
       "      <td>15:40:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  train_loss  valid_loss  accuracy      time\n",
       "0      0    3.726073    3.523209  0.375969  15:40:15"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('lang_model_onecycle/history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text.models import AWD_LSTM\n",
    "from fastai.text import TextLMDataBunch as lmdb, load_data\n",
    "from fastai.text.learner import language_model_learner\n",
    "from fastai.basic_train import load_learner\n",
    "path = Path('lang_model_onecycle/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_through(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't have to execute the below cell anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (16385650 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxunk throws exception when adding product via xxup api xxxfldbody xxmaj if xxmaj google xxmaj contents xxmaj experiments is enabled , adding a product using the xxxcdb xxup v1 / products / xxxcde endpoint causes xxunk xxxfilepath line 117 to throw xxxcdb invalidargumentexception xxxcde . xxmaj with contents experiments disabled the product add completes successfully . xxmaj example valid request json : \n",
       "  xxxcdb \" product \" : xxxjson \n",
       "  xxxcde,xxbos xxxfldtitle xxmaj grafana xxmaj kairosdb xxmaj top n rows xxxfldbody xxmaj when xxmaj grafana pulls the data it shows all the rows returned by the query , so can we please have a query option with something like xxunk ? xxmaj so we can only show limited number of rows on xxmaj grafana unlike now it just gets and shows everything . i have also requested a xxup ui option with xxmaj grafana guys where we can choose the number of rows we want to see under the graph , cheers,xxbos xxxfldtitle xxmaj graph request : mouseover highlight curve . xxxfldbody xxmaj it would be very nice , is mouseover of an item in graph legend ( to the left ) , or mouseover a graphed value ( with checkbox like xxup xxunk ) - would plot that value with double thickness . xxmaj that would make it easy to identify line for each value .,xxbos xxxfldtitle xxmaj graphite template to handle ip - address and hostname xxxfldbody xxmaj are there any plans to improve the graphite template logic ? xxmaj we are sending graphite data that contains xxup ip address and hostname ( xxunk , xxunk , etc ) , since those values have dot 's in them , it makes it difficult to identify tags for those graphite values . xxmaj one other issue we are having is identifying multiple tags in the middle of the graphite string to create a measurement .,xxbos xxxfldtitle xxmaj graphs : xxunk xxxfldbody xxmaj project : xxmaj graphs \n",
       "  xxmaj job : xxup uat \n",
       "  xxmaj env : xxup uat \n",
       "  xxmaj region : fxlabs / xxup us_west_1 \n",
       "  xxmaj result : fail \n",
       "  xxmaj status xxmaj code : 400 \n",
       "  xxmaj headers : xxunk x - xxup xss - xxmaj protection=[1 ; mode = block ] , xxmaj cache - xxmaj control=[no - cache , no - store , max - age=0 , must - revalidate ] , xxmaj pragma=[no - cache ] , xxmaj expires=[0 ] , x - xxmaj frame - options=[deny ] , xxunk xxmaj transfer - xxmaj encoding=[chunked ] , date=[tue , 02 xxmaj oct 2018 xxunk xxup gmt ] } \n",
       "  xxmaj endpoint : * xxup url * xxxlnkhb xxunk xxxlnkhe \n",
       "  xxmaj request : \n",
       "  xxmaj response : \n",
       "  xxxjson \n",
       "  xxmaj logs : \n",
       "  xxmaj assertion xxxatmention = = 403 ] resolved - to [ 400 = = 403 ] result [ xxmaj failed ] --- xxup fx xxmaj bot ---\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Valid: LabelList (1862119 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxmaj gopi xxmaj episode 98 xxxfldbody xxmaj gopi xxmaj episode 98 xxxhtml * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml via xxmaj juragan xxmaj sinopsis * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml xxmaj december 17 , 2016 at xxup xxunk,xxbos xxxfldtitle xxmaj grabber with default xxunk model xxxfldbody xxxhm xxmaj overview \n",
       "  i want to use the default xxunk model ( loaded via dll ) to work with the grabber script . xxmaj the xxunk - demo uses xxunk controller block - shaped prefabs to add the grabber script , but i would like to actually use the default models . xxmaj how would i go about doing so ? \n",
       "  xxxhm xxmaj unity xxmaj editor xxmaj version \n",
       "  xxunk \n",
       "  xxxhm xxmaj mixed xxmaj reality xxmaj toolkit xxmaj release xxmaj version \n",
       "  xxunk xxmaj hot xxmaj fix,xxbos xxxfldtitle graphql integration xxxfldbody xxmaj hi ! xxmaj this project looks really promising to build a modern webapp ðŸ˜Š i 've been hoping for something like this for a long time ! xxmaj however my first criterion is integrating with a graphql backend , which i even plan to be a hosted backend ( xxmaj graphcool xxxlnkhb * xxup url * xxxlnkhe ) . i suppose it 's not possible right now to use xxmaj xxunk in conjunction with xxmaj graphcool , but could it be considered in the design ? xxmaj the best would be to come up with a standard which can be plugged into any graphql backend ( hosted or own ) . xxmaj thanks so much and all the best,xxbos xxxfldtitle xxmaj grass toolbox filter input is n't labelled xxxfldbody xxxhr xxmaj author xxmaj name : xxunk - ( xxunk - ) xxmaj original xxmaj redmine xxmaj issue : xxunk , * xxup url * xxxlnkhb issues.qgis.org xxxlnkhe \n",
       "  xxxhr xxmaj if you open the xxup grass tools and choose the module list tab , there 's a text input field below the list which filters the list of modules . xxmaj however there 's no clue that it 's a filter box ! xxmaj we had some students confused by this on a course recently . \n",
       "  xxmaj needs a xxmaj filter : label on that line . xxmaj relevant xxup ui file is xxunk i guess .,xxbos xxxfldtitle xxmaj great program -- problems with kotlin xxxfldbody xxmaj quickly trying out your program - awesome . a few quick problems : decompiling a directory of kotlin ... a crash and some mis - ordered xxunk . crash : \n",
       "  xxunk xxxlnkhb github.com xxxlnkhe xxmaj xxunk : \n",
       "  xxup xxunk xxxlnkhb github.com xxxlnkhe xxunk xxxlnkhb github.com xxxlnkhe\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe85dc5fae8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('lang_model_onecycle_resume'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: LanguageLearner(data=TextLMDataBunch;\n",
       "\n",
       "Train: LabelList (16385650 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxunk throws exception when adding product via xxup api xxxfldbody xxmaj if xxmaj google xxmaj contents xxmaj experiments is enabled , adding a product using the xxxcdb xxup v1 / products / xxxcde endpoint causes xxunk xxxfilepath line 117 to throw xxxcdb invalidargumentexception xxxcde . xxmaj with contents experiments disabled the product add completes successfully . xxmaj example valid request json : \n",
       "  xxxcdb \" product \" : xxxjson \n",
       "  xxxcde,xxbos xxxfldtitle xxmaj grafana xxmaj kairosdb xxmaj top n rows xxxfldbody xxmaj when xxmaj grafana pulls the data it shows all the rows returned by the query , so can we please have a query option with something like xxunk ? xxmaj so we can only show limited number of rows on xxmaj grafana unlike now it just gets and shows everything . i have also requested a xxup ui option with xxmaj grafana guys where we can choose the number of rows we want to see under the graph , cheers,xxbos xxxfldtitle xxmaj graph request : mouseover highlight curve . xxxfldbody xxmaj it would be very nice , is mouseover of an item in graph legend ( to the left ) , or mouseover a graphed value ( with checkbox like xxup xxunk ) - would plot that value with double thickness . xxmaj that would make it easy to identify line for each value .,xxbos xxxfldtitle xxmaj graphite template to handle ip - address and hostname xxxfldbody xxmaj are there any plans to improve the graphite template logic ? xxmaj we are sending graphite data that contains xxup ip address and hostname ( xxunk , xxunk , etc ) , since those values have dot 's in them , it makes it difficult to identify tags for those graphite values . xxmaj one other issue we are having is identifying multiple tags in the middle of the graphite string to create a measurement .,xxbos xxxfldtitle xxmaj graphs : xxunk xxxfldbody xxmaj project : xxmaj graphs \n",
       "  xxmaj job : xxup uat \n",
       "  xxmaj env : xxup uat \n",
       "  xxmaj region : fxlabs / xxup us_west_1 \n",
       "  xxmaj result : fail \n",
       "  xxmaj status xxmaj code : 400 \n",
       "  xxmaj headers : xxunk x - xxup xss - xxmaj protection=[1 ; mode = block ] , xxmaj cache - xxmaj control=[no - cache , no - store , max - age=0 , must - revalidate ] , xxmaj pragma=[no - cache ] , xxmaj expires=[0 ] , x - xxmaj frame - options=[deny ] , xxunk xxmaj transfer - xxmaj encoding=[chunked ] , date=[tue , 02 xxmaj oct 2018 xxunk xxup gmt ] } \n",
       "  xxmaj endpoint : * xxup url * xxxlnkhb xxunk xxxlnkhe \n",
       "  xxmaj request : \n",
       "  xxmaj response : \n",
       "  xxxjson \n",
       "  xxmaj logs : \n",
       "  xxmaj assertion xxxatmention = = 403 ] resolved - to [ 400 = = 403 ] result [ xxmaj failed ] --- xxup fx xxmaj bot ---\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Valid: LabelList (1862119 items)\n",
       "x: LMTextList\n",
       "xxbos xxxfldtitle xxmaj gopi xxmaj episode 98 xxxfldbody xxmaj gopi xxmaj episode 98 xxxhtml * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml via xxmaj juragan xxmaj sinopsis * xxup url * xxxlnkhb ift.tt xxxlnkhe xxxhtml xxmaj december 17 , 2016 at xxup xxunk,xxbos xxxfldtitle xxmaj grabber with default xxunk model xxxfldbody xxxhm xxmaj overview \n",
       "  i want to use the default xxunk model ( loaded via dll ) to work with the grabber script . xxmaj the xxunk - demo uses xxunk controller block - shaped prefabs to add the grabber script , but i would like to actually use the default models . xxmaj how would i go about doing so ? \n",
       "  xxxhm xxmaj unity xxmaj editor xxmaj version \n",
       "  xxunk \n",
       "  xxxhm xxmaj mixed xxmaj reality xxmaj toolkit xxmaj release xxmaj version \n",
       "  xxunk xxmaj hot xxmaj fix,xxbos xxxfldtitle graphql integration xxxfldbody xxmaj hi ! xxmaj this project looks really promising to build a modern webapp ðŸ˜Š i 've been hoping for something like this for a long time ! xxmaj however my first criterion is integrating with a graphql backend , which i even plan to be a hosted backend ( xxmaj graphcool xxxlnkhb * xxup url * xxxlnkhe ) . i suppose it 's not possible right now to use xxmaj xxunk in conjunction with xxmaj graphcool , but could it be considered in the design ? xxmaj the best would be to come up with a standard which can be plugged into any graphql backend ( hosted or own ) . xxmaj thanks so much and all the best,xxbos xxxfldtitle xxmaj grass toolbox filter input is n't labelled xxxfldbody xxxhr xxmaj author xxmaj name : xxunk - ( xxunk - ) xxmaj original xxmaj redmine xxmaj issue : xxunk , * xxup url * xxxlnkhb issues.qgis.org xxxlnkhe \n",
       "  xxxhr xxmaj if you open the xxup grass tools and choose the module list tab , there 's a text input field below the list which filters the list of modules . xxmaj however there 's no clue that it 's a filter box ! xxmaj we had some students confused by this on a course recently . \n",
       "  xxmaj needs a xxmaj filter : label on that line . xxmaj relevant xxup ui file is xxunk i guess .,xxbos xxxfldtitle xxmaj great program -- problems with kotlin xxxfldbody xxmaj quickly trying out your program - awesome . a few quick problems : decompiling a directory of kotlin ... a crash and some mis - ordered xxunk . crash : \n",
       "  xxunk xxxlnkhb github.com xxxlnkhe xxmaj xxunk : \n",
       "  xxup xxunk xxxlnkhb github.com xxxlnkhe xxunk xxxlnkhb github.com xxxlnkhe\n",
       "y: LMLabelList\n",
       ",,,,\n",
       "Path: lang_model;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fe85dc5fae8>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('lang_model_onecycle_resume'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=None)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 1150, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1150, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): Embedding(60003, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(60003, 400, padding_idx=1)\n",
       "  )\n",
       "  (2): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")], add_time=True, silent=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lm = load_data(path, bs=128)\n",
    "\n",
    "learn = language_model_learner(data=data_lm,\n",
    "                               arch=AWD_LSTM,\n",
    "                               pretrained=False)\n",
    "\n",
    "learn.load('bestmodel')\n",
    "\n",
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# previous Loss: [3.390915, tensor(0.3917)] for langmodel_onecycle_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.390915, tensor(0.3917)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(60003, 400, padding_idx=1)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(60003, 400, padding_idx=1)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=60003, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.model.reset() # so the hidden states reset between predictions\n",
    "_ = learn.model.eval() # turn off dropout, etc. only need to do this after loading model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "\n",
    "Fastai encoder produces a tuple of two lists `raw_output` and `output`.  see [this reference](https://github.com/fastai/fastai/blob/master/fastai/text/models/awd_lstm.py#L123)  `raw_output` are the hidden states emitted for each element of the sequence without dropout.  Because you are turning off dropout during inference with `.eval()`, it really doesn't matter which one you get as they will both be the same (if they are not, this is a bug). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxxfldtitle v1alpha2 implement condition update xxxfldbody we should update the conditions according to the status. \\ r \\ r / cc xxxatmention \n"
     ]
    }
   ],
   "source": [
    "ex = processed_issue_texts[0]['text']\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,    22, 35652,   454,  1619,   173,    23,    64,    66,   173,\n",
       "             9,  2127,  1099,    13,     9,   357,    10,    50,   696,    50,\n",
       "           696,    37,  1075,   118]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_numericalized_x,  ex_numericalized_y = learn.data.one_item(ex)\n",
    "ex_numericalized_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two output tensors should be the same, this is testing that the model state is being reset correctly between predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0129,  0.0362,  0.0007,  ..., -0.0754, -0.0074,  0.0045],\n",
      "         [-0.0251,  0.0263,  0.0664,  ..., -0.0272,  0.0092,  0.0330],\n",
      "         [ 0.0580,  0.0300,  0.0196,  ..., -0.0416,  0.0290,  0.0129],\n",
      "         ...,\n",
      "         [-0.0111,  0.0130,  0.0432,  ..., -0.0640,  0.1140,  0.0357],\n",
      "         [-0.0105, -0.0146,  0.0293,  ..., -0.1969,  0.2049,  0.0006],\n",
      "         [-0.0057,  0.0225,  0.0220,  ..., -0.1356, -0.0231, -0.0011]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 24, 400])\n"
     ]
    }
   ],
   "source": [
    "encoder = learn.model[0]\n",
    "rep = encoder.forward(ex_numericalized_x)[-1][-1]\n",
    "print(rep)\n",
    "print(rep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0129,  0.0362,  0.0007,  ..., -0.0754, -0.0074,  0.0045],\n",
      "         [-0.0251,  0.0263,  0.0664,  ..., -0.0272,  0.0092,  0.0330],\n",
      "         [ 0.0580,  0.0300,  0.0196,  ..., -0.0416,  0.0290,  0.0129],\n",
      "         ...,\n",
      "         [-0.0111,  0.0130,  0.0432,  ..., -0.0640,  0.1140,  0.0357],\n",
      "         [-0.0105, -0.0146,  0.0293,  ..., -0.1969,  0.2049,  0.0006],\n",
      "         [-0.0057,  0.0225,  0.0220,  ..., -0.1356, -0.0231, -0.0011]]],\n",
      "       grad_fn=<TransposeBackward0>)\n",
      "torch.Size([1, 24, 400])\n"
     ]
    }
   ],
   "source": [
    "learn.model.reset()\n",
    "rep = encoder.forward(ex_numericalized_x)[-1][-1]\n",
    "print(rep)\n",
    "print(rep.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numericalized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4b4d4a81934c60a22b34b9c6352da9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# index into [0] b/c we don't care about the y value.\n",
    "num_x = []\n",
    "\n",
    "for x in tqdm_notebook(processed_issue_texts, total=len(processed_issue_texts)):\n",
    "    num_x.extend(learn.data.one_item(x)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ecb659f82d4adbbff9479bcbc8f8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1384), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reps=[]\n",
    "for x in tqdm_notebook(num_x, total=len(num_x)):\n",
    "    encoder.reset()\n",
    "    reps.extend(encoder.forward(x[None, :])[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "class IssueRepresentation:\n",
    "    \n",
    "    def __init__(self, tensor:torch.tensor) -> torch.tensor:\n",
    "        self.tensor=tensor\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return torch.mean(self.tensor, 0)\n",
    "    \n",
    "    @property\n",
    "    def max(self):\n",
    "        return torch.max(self.tensor, 0)[0]\n",
    "    \n",
    "    @property\n",
    "    def last(self):\n",
    "        return self.tensor[-1,:]\n",
    "    \n",
    "    @property\n",
    "    def concat(self):\n",
    "        return torch.cat([self.mean, self.max, self.last])\n",
    "\n",
    "class IssueRepresentation_List:\n",
    "    def __init__(self, irl=List[torch.tensor]):\n",
    "        self.irl = [IssueRepresentation(x) for x in irl]\n",
    "    \n",
    "    @property\n",
    "    def mean(self):\n",
    "        return torch.stack([x.mean for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def max(self):\n",
    "        return torch.stack([x.max for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def last(self):\n",
    "        return torch.stack([x.last for x in self.irl])\n",
    "    \n",
    "    @property\n",
    "    def concat(self):\n",
    "        return torch.stack([x.concat for x in self.irl])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "irl = IssueRepresentation_List(reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('irl.pkl', 'wb') as f:\n",
    "    pkl.dump(irl, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if Naive One Shot Learning Works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "\n",
    "with open('irl.pkl', 'rb') as f:\n",
    "    irl = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542 issues w/o labels out of 1384 total issues.\n"
     ]
    }
   ],
   "source": [
    "## == True converts it into a 0/1 indices array\n",
    "candidates_to_label = torch.tensor((kfdf.labels == '[]').values) == True\n",
    "\n",
    "print(f'{candidates_to_label.sum()} issues w/o labels out of {len(kfdf)} total issues.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_label_reps = irl.concat[candidates_to_label]\n",
    "label_reps = irl.concat[~candidates_to_label]\n",
    "\n",
    "assert (no_label_reps.shape[0] + label_reps.shape[0]) == len(kfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mask = kfdf.labels != '[]'\n",
    "\n",
    "labeled_df = kfdf[label_mask].reset_index(drop=True)\n",
    "no_label_df = kfdf[~label_mask].reset_index(drop=True)\n",
    "\n",
    "assert len(labeled_df) + len(no_label_df) == len(kfdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "class oneshotlabeler:\n",
    "    def __init__(self, vecs, refdf):\n",
    "        assert vecs.shape[0] == len(refdf)\n",
    "        self.vecs = vecs\n",
    "        self.refdf = refdf.reset_index(drop=True)\n",
    "        self.cs = CosineSimilarity()\n",
    "    \n",
    "    def query(self, vec):\n",
    "        assert vec.ndim == 1\n",
    "        sims = cs.forward(vec.unsqueeze(0), self.vecs)\n",
    "        idxs = sims.argsort(descending=True)\n",
    "        ranked_sims = sims[idxs]\n",
    "        \n",
    "        closest_idx = idxs[0].item()\n",
    "        ref_issue = self.refdf.iloc[closest_idx]\n",
    "        \n",
    "        msg = []\n",
    "        msg.append(f'\\n## Prediction:\\n')\n",
    "        msg.append(f'**Predicted Labels**: {json.loads(ref_issue.labels)}\\n')\n",
    "        msg.append(f'**Cosine similarity (0-1)**: {ranked_sims[0]:.2f}\\n')\n",
    "        msg.append(f'**Closest Issue URL**: {json.loads(ref_issue.url)}\\n')\n",
    "        msg.append(f'**Closest Issue Title**: {ref_issue.title}\\n')\n",
    "        msg.append(f'**Closest Issue Body**:\\n {ref_issue.body[:600]}')\n",
    "        display(Markdown('\\n'.join(msg)))\n",
    "        \n",
    "    def random_prediction(self, no_label_df, no_label_vec):\n",
    "        assert len(no_label_df) == no_label_vec.shape[0]\n",
    "        sample = no_label_df.sample(1)\n",
    "        idx = sample.index.values[0]\n",
    "        \n",
    "        msg = []\n",
    "        msg.append(f'\\n## Un-Labeled Target Issue To Predict:\\n')\n",
    "        msg.append(f'**Title:** {sample.title.values[0]}\\n')\n",
    "        msg.append(f'**Body:**\\n {sample.body.values[0][:600]}\\n')\n",
    "        msg.append(f'**URL:** {sample.url.values[0]}')\n",
    "        display(Markdown('\\n'.join(msg)))\n",
    "        \n",
    "        self.query(no_label_vec[idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(no_label_df) == no_label_reps.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "ol = oneshotlabeler(vecs=label_reps, \n",
    "                    refdf = labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Un-Labeled Target Issue To Predict:\n",
       "\n",
       "**Title:** \\ kfctl apply k8s\\  fails to deploy scheduledworkflows on mac\n",
       "\n",
       "**Body:**\n",
       " hi, i'm trying to install kubeflow on \\ docker for mac with k8s\\  with these instructions from the  documentation  https://www.kubeflow.org/docs/started/getting-started-k8s/ .\\r \\r     environment\\r    \\r kubectl version\\r client version: version.info{major:\\ 1\\ , minor:\\ 10\\ , gitversion:\\ v1.10.11\\ , gitcommit:\\ 637c7e288581ee40ab4ca210618a89a555b6e7e9\\ , gittreestate:\\ clean\\ , builddate:\\ 2018-11-26t14:38:32z\\ , goversion:\\ go1.9.3\\ , compiler:\\ gc\\ , platform:\\ darwin/amd64\\ }\\r server version: version.info{major:\\ 1\\ , minor:\\ 10\\ , gitversion:\\ v1.10.11\\ , gitcommit:\\ 637c7e288581ee40ab\n",
       "\n",
       "**URL:** \"https://github.com/kubeflow/kubeflow/issues/3130\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "## Prediction:\n",
       "\n",
       "**Predicted Labels**: ['area/tfjob', 'kind/bug', 'priority/p1']\n",
       "\n",
       "**Cosine similarity (0-1)**: 0.95\n",
       "\n",
       "**Closest Issue URL**: https://github.com/kubeflow/kubeflow/issues/2634\n",
       "\n",
       "**Closest Issue Title**: kfctl apply failed for invalid spec.version when installing crd tfjobs.kubeflow.org\n",
       "\n",
       "**Closest Issue Body**:\n",
       " i'm initializing a kubeflow testing environment following offical getting started guide <https://www.kubeflow.org/docs/started/getting-started/>. here are the commands  just copy them from the webpage :\\r \\r    \\r export kubeflow_src=$ pwd /kubeflow\\r \\r mkdir ${kubeflow_src}\\r cd ${kubeflow_src}\\r export kubeflow_tag=v0.4.1\\r \\r curl https://raw.githubusercontent.com/kubeflow/kubeflow/${kubeflow_tag}/scripts/download.sh | bash\\r \\r export kfapp=kfapp\\r ${kubeflow_src}/scripts/kfctl.sh init ${kfapp} --platform none\\r cd ${kfapp}\\r ${kubeflow_src}/scripts/kfctl.sh generate k8s\\r ${kubeflow_src}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ol.random_prediction(no_label_df=no_label_df,\n",
    "                     no_label_vec=no_label_reps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- Some labels have a fairly high N.  Do we really need few shot for these?\n",
    "- Do you really want to maintain local models for each repo?  If you do should be a seperate service with API endpoint to keep dependencies clean.\n",
    "- First lets see if few shot can even work?\n",
    "- Looks like we might be able to get pretty far on keyword matching and BPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning On Kubeflow/* (the whole org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get Data That has at least one label that occurs > 20 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, Set\n",
    "label_counter = Counter()\n",
    "\n",
    "df['labels_unpacked'] = df.labels.apply(lambda x: unpack_list(x))\n",
    "\n",
    "for labels in df.labels_unpacked:\n",
    "    label_counter.update(labels)\n",
    "    \n",
    "labels_to_keep = {x:label_counter[x] for x in label_counter if label_counter[x] >= 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the labels that occur > 20 times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'api/v1alpha2': 78,\n",
       " 'area/operator': 51,\n",
       " 'kind/enhancement': 34,\n",
       " 'priority/p0': 167,\n",
       " 'area/front-end': 136,\n",
       " 'priority/p1': 902,\n",
       " 'release/0.2.0': 67,\n",
       " 'release/0.3.0': 195,\n",
       " 'sprint/2018-06-11-to-06-22': 28,\n",
       " 'area/0.4.0': 130,\n",
       " 'area/docs': 117,\n",
       " 'area/testing': 138,\n",
       " 'help wanted': 122,\n",
       " 'addition/feature': 42,\n",
       " 'kind/bug': 130,\n",
       " 'problems/bug': 28,\n",
       " 'area/bootstrap': 83,\n",
       " 'platform/gcp': 138,\n",
       " 'testing': 90,\n",
       " 'area/0.3.0': 28,\n",
       " 'good first issue': 71,\n",
       " 'improvement/enhancement': 40,\n",
       " 'community/discussion': 30,\n",
       " 'priority/p3': 40,\n",
       " 'area/api': 28,\n",
       " 'area/jupyter': 145,\n",
       " 'sprint/2018-07-09-to-07-20': 20,\n",
       " 'area/back-end': 27,\n",
       " 'area/tfjob': 47,\n",
       " 'priority/p2': 284,\n",
       " 'area/example/code_search': 45,\n",
       " 'kind/feature': 44,\n",
       " 'area/0.5.0': 40,\n",
       " 'community/question': 150,\n",
       " 'inference': 27,\n",
       " 'area/kfctl': 116,\n",
       " 'area/build-release': 61,\n",
       " 'area/inference': 60,\n",
       " 'area/ksonnet': 24,\n",
       " 'cuj/multi-user': 30,\n",
       " 'cuj/build-train-deploy': 31}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Number of labels: 41\n"
     ]
    }
   ],
   "source": [
    "display(labels_to_keep)\n",
    "print(f' Number of labels: {len(labels_to_keep)}')\n",
    "\n",
    "label_set = set(labels_to_keep.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1687, 7)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h_labeled_df = df[df.labels_unpacked.apply(lambda x: len(set(x).intersection(label_set)) > 0)]\n",
    "h_labeled_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only retain labels that occur at least 20 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "h_labeled_df['final_labels'] = h_labeled_df.labels_unpacked.apply(lambda x: set(x).intersection(label_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extract One Hot Encoded Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, ..., 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, ..., 1, 1, 0, 0],\n",
       "       [0, 1, 0, 1, ..., 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, ..., 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, ..., 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 0, 0],\n",
       "       [1, 1, 0, 1, ..., 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, ..., 0, 0, 0, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1687, 41)\n"
     ]
    }
   ],
   "source": [
    "ohe_labels = mlb.fit_transform(h_labeled_df.final_labels.values.tolist())\n",
    "display(ohe_labels)\n",
    "print(ohe_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['addition/feature', 'api/v1alpha2', 'area/0.3.0', 'area/0.4.0', 'area/0.5.0', 'area/api', 'area/back-end',\n",
       "       'area/bootstrap', 'area/build-release', 'area/docs', 'area/example/code_search', 'area/front-end',\n",
       "       'area/inference', 'area/jupyter', 'area/kfctl', 'area/ksonnet', 'area/operator', 'area/testing', 'area/tfjob',\n",
       "       'community/discussion', 'community/question', 'cuj/build-train-deploy', 'cuj/multi-user', 'good first issue',\n",
       "       'help wanted', 'improvement/enhancement', 'inference', 'kind/bug', 'kind/enhancement', 'kind/feature',\n",
       "       'platform/gcp', 'priority/p0', 'priority/p1', 'priority/p2', 'priority/p3', 'problems/bug', 'release/0.2.0',\n",
       "       'release/0.3.0', 'sprint/2018-06-11-to-06-22', 'sprint/2018-07-09-to-07-20', 'testing'], dtype=object)"
      ]
     },
     "execution_count": 776,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract Latent Features For Each Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbdbe81dbbfe45d8a7456cac9f312a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1687), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_text = [process_dict(x, 0) for x in labeled_df.to_dict(orient='rows')]\n",
    "vecs = []\n",
    "encoder = learn.model[0]\n",
    "encoder.eval()\n",
    "\n",
    "for x in tqdm_notebook(cleaned_text, total=len(cleaned_text)):\n",
    "    # transform the data to integers\n",
    "    x = learn.data.one_item(x)[0]\n",
    "    # forward to pass through model\n",
    "    encoder.reset()\n",
    "    vecs.extend(encoder.forward(x)[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_list = IssueRepresentation_List(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0467,  0.0119,  0.0663,  ..., -0.0782, -0.0304, -0.0003],\n",
       "        [ 0.0970,  0.0110, -0.0078,  ..., -0.0838, -0.0189,  0.0131],\n",
       "        [ 0.0591,  0.0070,  0.0389,  ..., -0.0966, -0.0313,  0.0013],\n",
       "        ...,\n",
       "        [ 0.0703,  0.0162, -0.0188,  ..., -0.0941, -0.0271, -0.0014],\n",
       "        [ 0.0736, -0.0151,  0.0031,  ..., -0.0619, -0.0281, -0.0016],\n",
       "        [ 0.0621, -0.0010,  0.0237,  ..., -0.1155, -0.0385, -0.0002]],\n",
       "       grad_fn=<StackBackward>)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1687, 1200])\n"
     ]
    }
   ],
   "source": [
    "latent_features = vec_list.concat\n",
    "display(latent_features)\n",
    "print(latent_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Extract Repo Indicators (Additional Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 19 repos in the dataset with labels\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {h_labeled_df.repo.nunique()} repos in the dataset with labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, ..., 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, ..., 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, ..., 0, 0, 1, 0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1687, 19)"
      ]
     },
     "execution_count": 773,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlb_repos = MultiLabelBinarizer()\n",
    "\n",
    "repo_indicators = mlb_repos.fit_transform([[x] for x in h_labeled_df.repo.values.tolist()])\n",
    "display(repo_indicators)\n",
    "repo_indicators.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Combine Feautre Vectors & Train Model 5-Fold CV, Keep Out-of-Fold preds\n",
    "\n",
    "Concat Repo Indicators and Latent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1687, 1219)"
      ]
     },
     "execution_count": 504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "feature_arr = np.concatenate([repo_indicators, latent_features], axis = 1)\n",
    "feature_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/c7/401c231c445fb6fad135e92197da9c3e77983de169ff1887cc18af94498d/scikit_learn-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.7MB 19.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.13.2)\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.21.0\n",
      "    Uninstalling scikit-learn-0.21.0:\n",
      "      Successfully uninstalled scikit-learn-0.21.0\n",
      "Successfully installed scikit-learn-0.21.1\n"
     ]
    }
   ],
   "source": [
    "! pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.0'"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.neural_network.MLPClassifier\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "etc = ExtraTreesClassifier(n_estimators=100, min_samples_leaf=2, bootstrap=False, n_jobs=-1)\n",
    "knn = KNeighborsClassifier(n_neighbors=2, weights='distance', metric='cosine', n_jobs=-1)\n",
    "rc = RidgeClassifierCV(alphas=[.1, .5, 5, 10, 50, 100], normalize=True, store_cv_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(alpha=.01, \n",
    "                    hidden_layer_sizes=(500,),\n",
    "                    learning_rate='adaptive', \n",
    "                    learning_rate_init=.1, \n",
    "                    early_stopping=True, \n",
    "                    validation_fraction=.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.01, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(500,), learning_rate='adaptive',\n",
       "              learning_rate_init=0.1, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.25, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 848,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=np.delete(feature_arr, pred_index, axis=0),\n",
    "        y=np.delete(ohe_labels, pred_index, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.800422804439018e-05   addition/feature\n",
      "0.004316295039701864   api/v1alpha2\n",
      "5.649512418352858e-05   area/0.3.0\n",
      "0.08840352694439761   area/0.4.0\n",
      "9.026766555145957e-05   area/0.5.0\n",
      "2.8259444307727876e-05   area/api\n",
      "0.00434346014321032   area/back-end\n",
      "0.024164074913004662   area/bootstrap\n",
      "0.06470222263188   area/build-release\n",
      "0.0937456735331016   area/docs\n",
      "0.002476910030106788   area/example/code_search\n",
      "*** 0.07005119531342831   area/front-end\n",
      "0.0400206659764553   area/inference\n",
      "0.08157587854703642   area/jupyter\n",
      "0.0609930105802697   area/kfctl\n",
      "0.015836785437453937   area/ksonnet\n",
      "0.02912750816976115   area/operator\n",
      "0.10465119971930756   area/testing\n",
      "0.002670841714019011   area/tfjob\n",
      "0.006456681244973385   community/discussion\n",
      "0.007324003218792524   community/question\n",
      "0.022002275579410747   cuj/build-train-deploy\n",
      "0.01269626922120256   cuj/multi-user\n",
      "0.05254902484630349   good first issue\n",
      "0.0695335347299035   help wanted\n",
      "0.00016611675694153008   improvement/enhancement\n",
      "0.0017730967490715611   inference\n",
      "0.0776168961705274   kind/bug\n",
      "0.0069148434294968265   kind/enhancement\n",
      "0.0019111186845026853   kind/feature\n",
      "0.0006896978848769677   platform/gcp\n",
      "0.10813692048246774   priority/p0\n",
      "*** 0.6955454644727967   priority/p1\n",
      "0.15374017261981285   priority/p2\n",
      "0.02934454331439272   priority/p3\n",
      "0.0012741408243957598   problems/bug\n",
      "*** 0.005526174342339448   release/0.2.0\n",
      "*** 0.04561568608796274   release/0.3.0\n",
      "*** 0.005336582094342152   sprint/2018-06-11-to-06-22\n",
      "0.0009323752051200633   sprint/2018-07-09-to-07-20\n",
      "0.09014346870401345   testing\n"
     ]
    }
   ],
   "source": [
    "preds = clf.predict_proba(feature_arr[None, pred_index])\n",
    "ground_truth = ohe_labels[pred_index, :] == 1\n",
    "\n",
    "for g,p,c in zip(ground_truth.tolist(), preds[0, :].tolist(), mlb.classes_.tolist()):\n",
    "    if g:\n",
    "        print('***', p,' ', c)\n",
    "    else:\n",
    "        print(p,' ', c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 41)"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(feature_arr[None, pred_index]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [],
   "source": [
    "drdf = pd.DataFrame(feature_arr)\n",
    "drdf['target'] = ohe_labels[:, 0]\n",
    "drdf.columns = ['f_'+ str(x) for x in drdf.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [],
   "source": [
    "drdf.to_csv('drdf_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1687, 1219)"
      ]
     },
     "execution_count": 865,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 875,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_labels[:, 0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_textdrdf = pd.DataFrame({'text': [x['text'] for x in cleaned_text], 'target': ohe_labels[:, 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xxxfldtitle v1alpha2 implement condition update xxxfldbody we should update the conditions according to the status. \\ r \\ r / cc xxxatmention</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xxxfldtitle tfjobs ui doesn't work behind iap; react app needs support iap? xxxfldbody tfjobs ui is deployed on dev.kubeflow.org. \\ r \\ r the ui shows up behind iap but its doesn't work \\ r - no tfjobs are listed \\ r - creating a job via the ui doesn't work. \\ r \\ r looking at the developer console we see requests to \\ r \\ r \\ r *URL* xxxlnkhb accounts.google.com xxxlnkhe \\ r \\ r which suggests to me the request is hitting the loadbalancer and being directed to do auth verification to sign i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xxxfldtitle docs add instructions about how to contribute e2e test cases xxxfldbody ref *URL* xxxlnkhb github.com xxxlnkhe \\ r i think we need to have a doc about how to write e2e test cases for operators, which will lower the barriers of participation. in the best case, the doc could be also helpful for pytorch and mxnet operators. \\ r \\ r / cc xxxatmention</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>xxxfldtitle v1alpha2 error when host name is not svc.cluster.local xxxfldbody there are some k8s clusters which have their own domains, they may not use svc.cluster.local. then the service is configured to it, thus it won't work.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>xxxfldtitle gcp cluster-kubeflow.yaml isn't tested xxxfldbody this is the recommended dm and bootstrapper config for gke deployments. \\ r *URL* xxxlnkhb github.com xxxlnkhe \\ r it doesn't like that yaml file is used by our e2e tests because it wasn't updated to specify the registry when that change was made to \\ r *URL* xxxlnkhb github.com xxxlnkhe \\ r there is also another gcp bootstrapper config in that directory \\ r \\ r our e2e tests are using this dm config \\ r *URL* xxxlnkhb github.com ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  text  target\n",
       "0                                                                                                                                                                                                                                                                                                                                                                       xxxfldtitle v1alpha2 implement condition update xxxfldbody we should update the conditions according to the status. \\ r \\ r / cc xxxatmention        0\n",
       "1  xxxfldtitle tfjobs ui doesn't work behind iap; react app needs support iap? xxxfldbody tfjobs ui is deployed on dev.kubeflow.org. \\ r \\ r the ui shows up behind iap but its doesn't work \\ r - no tfjobs are listed \\ r - creating a job via the ui doesn't work. \\ r \\ r looking at the developer console we see requests to \\ r \\ r \\ r *URL* xxxlnkhb accounts.google.com xxxlnkhe \\ r \\ r which suggests to me the request is hitting the loadbalancer and being directed to do auth verification to sign i...       0\n",
       "2                                                                                                                                            xxxfldtitle docs add instructions about how to contribute e2e test cases xxxfldbody ref *URL* xxxlnkhb github.com xxxlnkhe \\ r i think we need to have a doc about how to write e2e test cases for operators, which will lower the barriers of participation. in the best case, the doc could be also helpful for pytorch and mxnet operators. \\ r \\ r / cc xxxatmention        0\n",
       "3                                                                                                                                                                                                                                                                                xxxfldtitle v1alpha2 error when host name is not svc.cluster.local xxxfldbody there are some k8s clusters which have their own domains, they may not use svc.cluster.local. then the service is configured to it, thus it won't work.       1\n",
       "4  xxxfldtitle gcp cluster-kubeflow.yaml isn't tested xxxfldbody this is the recommended dm and bootstrapper config for gke deployments. \\ r *URL* xxxlnkhb github.com xxxlnkhe \\ r it doesn't like that yaml file is used by our e2e tests because it wasn't updated to specify the registry when that change was made to \\ r *URL* xxxlnkhb github.com xxxlnkhe \\ r there is also another gcp bootstrapper config in that directory \\ r \\ r our e2e tests are using this dm config \\ r *URL* xxxlnkhb github.com ...       0"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_textdrdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_textdrdf.to_csv('raw_textdrdf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempdf = pd.DataFrame(feature_arr)\n",
    "tempdf.columns = ['f_'+ str(x) for x in tempdf.columns.tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {},
   "outputs": [],
   "source": [
    "drdf_concat  = pd.concat([raw_textdf, tempdf, pd.DataFrame({'target': ohe_labels[:, 0]})], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "drdf_concat.to_csv('drdf_concat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'f_0', 'f_1', 'f_2', 'f_3', 'f_4', 'f_5', 'f_6', 'f_7', 'f_8',\n",
       "       ...\n",
       "       'f_1210', 'f_1211', 'f_1212', 'f_1213', 'f_1214', 'f_1215', 'f_1216', 'f_1217', 'f_1218', 'target'], dtype='object', length=1221)"
      ]
     },
     "execution_count": 895,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drdf_concat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c3abe1761bb7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmlb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mlb' is not defined"
     ]
    }
   ],
   "source": [
    "mlb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
